{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c2755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Toxic-Spans-Detection'...\r\n"
     ]
    }
   ],
   "source": [
    "# clone our github repository\n",
    "!git clone https://github.com/Azzam-Radman/Toxic-Spans-Detection.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9dc11bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# prevent truncation of long sentences during displaying\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff0b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the datasets\n",
    "try:\n",
    "    # will be implimented if the repo is cloned\n",
    "    df1 = pd.read_excel('/content/Toxic-Spans-Detection/src/dataset/tokenized_1.xlsx')\n",
    "    df2 = pd.read_excel('/content/Toxic-Spans-Detection/src/dataset/tokenized_ready.xlsx')\n",
    "except:\n",
    "    # else read the datasets directly from the repo\n",
    "    df1 = pd.read_excel('https://github.com/Azzam-Radman/Toxic-Spans-Detection/blob/main/src/dataset/tokenized_1.xlsx?raw=true')\n",
    "    df2 = pd.read_excel('https://github.com/Azzam-Radman/Toxic-Spans-Detection/blob/main/src/dataset/tokenized_ready.xlsx?raw=true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecc76bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>اربد</td>\n",
       "      <td>فيها</td>\n",
       "      <td>جامعات</td>\n",
       "      <td>اكثر</td>\n",
       "      <td>من</td>\n",
       "      <td>عمان</td>\n",
       "      <td>...</td>\n",
       "      <td>وفيها</td>\n",
       "      <td>قد</td>\n",
       "      <td>عمان</td>\n",
       "      <td>...</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>الحلو</td>\n",
       "      <td>انكم</td>\n",
       "      <td>بتحكوا</td>\n",
       "      <td>على</td>\n",
       "      <td>اساس</td>\n",
       "      <td>انو</td>\n",
       "      <td>الاردن</td>\n",
       "      <td>ما</td>\n",
       "      <td>فيه</td>\n",
       "      <td>فساد</td>\n",
       "      <td>...</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>كله</td>\n",
       "      <td>رائع</td>\n",
       "      <td>بجد</td>\n",
       "      <td>ربنا</td>\n",
       "      <td>يكرمك</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>...</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "      <td>pad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 143 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1       2     3      4     5       6      7    8     9    ...  133  \\\n",
       "0   اربد  فيها  جامعات  اكثر     من  عمان     ...  وفيها   قد  عمان  ...  pad   \n",
       "1      0     0       0     0      0     0       0      0    0     0  ...  NaN   \n",
       "2  الحلو  انكم  بتحكوا   على   اساس   انو  الاردن     ما  فيه  فساد  ...  pad   \n",
       "3      0     0       0     0      0     0       0      0    0     0  ...  NaN   \n",
       "4    كله  رائع     بجد  ربنا  يكرمك   pad     pad    pad  pad   pad  ...  pad   \n",
       "\n",
       "   134  135  136  137  138  139  140  141  142  \n",
       "0  pad  pad  pad  pad  pad  pad  pad  pad  pad  \n",
       "1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2  pad  pad  pad  pad  pad  pad  pad  pad  pad  \n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "4  pad  pad  pad  pad  pad  pad  pad  pad  pad  \n",
       "\n",
       "[5 rows x 143 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate the two splits of the dataset\n",
    "df1 = df1.iloc[:1798, :].reset_index(drop=True)\n",
    "df2 = df2.iloc[1798:, :].reset_index(drop=True)\n",
    "# concatenate the two splits of the dataset\n",
    "df = pd.concat([df1, df2], axis=0).reset_index(drop=True)\n",
    "# display the head of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2fa79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove the 'pad' cells in the tokens rows\n",
    "# and remove the corresponding NaNs in the labels rows\n",
    "def remove_pad_nan(word_row, label_row):\n",
    "    \"\"\"\n",
    "    args:\n",
    "    word_row: the row containing words (tokens) with \"pad\" tokens to remove\n",
    "    label_row: the label containig labels (0 or 1) with NaNs to remove\n",
    "    returns two lists with words and labels without pads and NaNs.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    word_list = word_row.tolist()\n",
    "    label_list = label_row.tolist()\n",
    "    \n",
    "    word_list_cleaned = [word for word in word_list if word != 'pad']\n",
    "    label_list_cleaned = [label for label in label_list if label is not np.nan]\n",
    "    \n",
    "    pair = [word_list_cleaned, label_list_cleaned]\n",
    "    return pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abfb5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [] # initialize a list to hold the pairs\n",
    "# loop over each couple of rows and pass them to the previous function to extract\n",
    "# the cleaned rows without padding and NaNs\n",
    "for i in range(len(df)):\n",
    "    if i%2 == 0:\n",
    "        pairs.append(remove_pad_nan(df.iloc[i, :], df.iloc[i+1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "873553f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# ensure the lenght of each token row with its label row are equal\n",
    "# if there is a fault in the process the counter will be greater than 0\n",
    "counter = 0\n",
    "for pair in pairs: # loop over each pair of rows (tokens and labels)\n",
    "    if len(pair[0]) != len(pair[1]):\n",
    "        counter += 1\n",
    "        print(pair)\n",
    "print(counter)\n",
    "# since the counter value is still zero, every thing is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd69e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['اربد',\n",
       "  'فيها',\n",
       "  'جامعات',\n",
       "  'اكثر',\n",
       "  'من',\n",
       "  'عمان',\n",
       "  '...',\n",
       "  'وفيها',\n",
       "  'قد',\n",
       "  'عمان',\n",
       "  'ونص',\n",
       "  'لعيبه',\n",
       "  'المنتخب',\n",
       "  'منها',\n",
       "  '...',\n",
       "  'و',\n",
       "  80,\n",
       "  '%',\n",
       "  'من',\n",
       "  'مطربين',\n",
       "  'الاردن',\n",
       "  'منها'],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the first pair\n",
    "pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ba89076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a space after each token to reconstruct the sentences \n",
    "pairs_with_spaces = [] # initialize a list to hold the new pairs\n",
    "\n",
    "# loop over the pairs\n",
    "for pair in pairs:\n",
    "    words_with_spaces = [] # initialize a list for each iter in the loop to hold the tokens with the spaces\n",
    "    labels_with_spaces = [] # initialize a list for each iter in the loop to hold the labels with the spaces\n",
    "    len_one_pair = len(pair[0]) # extract the lenght of the list\n",
    "    \n",
    "    for i in range(len_one_pair): # loop over the list elements and add the space after each token and each label\n",
    "        words_with_spaces.extend([pair[0][i], ' '])\n",
    "        labels_with_spaces.extend([pair[1][i], ' '])\n",
    "    \n",
    "    new_pair = [words_with_spaces, labels_with_spaces] # create a new pair list of the tokens and labels with spaces\n",
    "    pairs_with_spaces.append(new_pair) # append new_pair list to the pairs_with_spaces list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe331432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# ensure the lenght of each token row with its label row are equal\n",
    "# if there is a fault in the process the counter will be greater than 0\n",
    "counter = 0\n",
    "for pair in pairs_with_spaces: # loop over each pair of rows (tokens and labels)\n",
    "    if len(pair[0]) != len(pair[1]):\n",
    "        counter += 1\n",
    "        \n",
    "print(counter)\n",
    "# since the counter value is still zero, every thing is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c91b909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove last space which was added after the last token and after the last label\n",
    "for pair in pairs_with_spaces:\n",
    "    pair[0].pop(-1)\n",
    "    pair[1].pop(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ccb1ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# ensure the lenght of each token row with its label row are equal\n",
    "# if there is a fault in the process the counter will be greater than 0\n",
    "counter = 0\n",
    "for pair in pairs_with_spaces: # loop over each pair of rows (tokens and labels)\n",
    "    if len(pair[0]) != len(pair[1]):\n",
    "        counter += 1\n",
    "        \n",
    "print(counter)\n",
    "# since the counter value is still zero, every thing is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "def3e93b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['اربد',\n",
       "  ' ',\n",
       "  'فيها',\n",
       "  ' ',\n",
       "  'جامعات',\n",
       "  ' ',\n",
       "  'اكثر',\n",
       "  ' ',\n",
       "  'من',\n",
       "  ' ',\n",
       "  'عمان',\n",
       "  ' ',\n",
       "  '...',\n",
       "  ' ',\n",
       "  'وفيها',\n",
       "  ' ',\n",
       "  'قد',\n",
       "  ' ',\n",
       "  'عمان',\n",
       "  ' ',\n",
       "  'ونص',\n",
       "  ' ',\n",
       "  'لعيبه',\n",
       "  ' ',\n",
       "  'المنتخب',\n",
       "  ' ',\n",
       "  'منها',\n",
       "  ' ',\n",
       "  '...',\n",
       "  ' ',\n",
       "  'و',\n",
       "  ' ',\n",
       "  80,\n",
       "  ' ',\n",
       "  '%',\n",
       "  ' ',\n",
       "  'من',\n",
       "  ' ',\n",
       "  'مطربين',\n",
       "  ' ',\n",
       "  'الاردن',\n",
       "  ' ',\n",
       "  'منها'],\n",
       " [0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the first pair\n",
    "pairs_with_spaces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c123451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each pair of the pairs_with_spaces list\n",
    "# if the label is 1 (toxic) extract its span\n",
    "# the span is the indexes of the underlying characters of each token\n",
    "for pair in pairs_with_spaces:\n",
    "    # length of the words or labels list\n",
    "    len_one_pair = len(pair[0])\n",
    "    # initialize the toxic spans list and a counter\n",
    "    toxic_spans_list = []\n",
    "    counter = 0\n",
    "    # loop over each item in each list\n",
    "    for idx in range(len_one_pair):\n",
    "        # extract word label from the label list\n",
    "        word_label = pair[1][idx]\n",
    "        # get the word length from the word list\n",
    "        if isinstance(pair[0][idx], str):\n",
    "            len_word = len(pair[0][idx]) # in case the token is a string extract its length\n",
    "        else: \n",
    "            len_word = 1 # else if the token is digit, its length is 1\n",
    "            \n",
    "        if word_label == 0:\n",
    "            counter += len_word # increment the counter by the number of characters of this token\n",
    "        elif word_label == ' ': # in case the token is a space increment the counter by 1\n",
    "            counter += 1\n",
    "        else:\n",
    "            toxic_spans = list(range(counter, counter+len_word)) # create a list of the toxic span of this token\n",
    "            toxic_spans_list.extend(toxic_spans) # extend the toxic spans list with the spans of the current toxic token\n",
    "            counter += len_word # increment the counter by 1\n",
    "            \n",
    "    pair.append(toxic_spans_list) # append the toxic spans list after each pair to the original pair list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e50ae075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['اربد',\n",
       "  ' ',\n",
       "  'فيها',\n",
       "  ' ',\n",
       "  'جامعات',\n",
       "  ' ',\n",
       "  'اكثر',\n",
       "  ' ',\n",
       "  'من',\n",
       "  ' ',\n",
       "  'عمان',\n",
       "  ' ',\n",
       "  '...',\n",
       "  ' ',\n",
       "  'وفيها',\n",
       "  ' ',\n",
       "  'قد',\n",
       "  ' ',\n",
       "  'عمان',\n",
       "  ' ',\n",
       "  'ونص',\n",
       "  ' ',\n",
       "  'لعيبه',\n",
       "  ' ',\n",
       "  'المنتخب',\n",
       "  ' ',\n",
       "  'منها',\n",
       "  ' ',\n",
       "  '...',\n",
       "  ' ',\n",
       "  'و',\n",
       "  ' ',\n",
       "  80,\n",
       "  ' ',\n",
       "  '%',\n",
       "  ' ',\n",
       "  'من',\n",
       "  ' ',\n",
       "  'مطربين',\n",
       "  ' ',\n",
       "  'الاردن',\n",
       "  ' ',\n",
       "  'منها'],\n",
       " [0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0,\n",
       "  ' ',\n",
       "  0],\n",
       " []]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the first pair\n",
    "pairs_with_spaces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b50cf54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct the sentences with the spans only \n",
    "last_pairs = [] # initialize a list to hold the final pairs (sentence, toxic spans)\n",
    "for pair in pairs_with_spaces: # loop over each pair\n",
    "    sentence = ''.join(map(str, pair[0])) # construct the sentece and ensure each element is a sting instance\n",
    "    spans = pair[-1] # the last list in each pair is the toxic spans\n",
    "    new_last_pair = [sentence, spans] # construct a new list with the sentece and toxic spans only\n",
    "    last_pairs.append(new_last_pair) # append this list to the last_pairs list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "277e82ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = np.zeros((len(df)//2, 2)) # initialize a zeros array to hold the place of the sentences and spans the \n",
    "                                  # final dataframe\n",
    "train_df = pd.DataFrame(zeros, columns=['Sentence', 'Spans']) # construct the final dataframe, all values are \n",
    "                                                              # initialized with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "965dc3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Spans'] = train_df['Spans'].astype('str') # change the Spans columns data type to string to accept lists\n",
    "for i in range(len(last_pairs)): # loop over each pair and populate the dataframe\n",
    "    train_df.iloc[i, 0] = last_pairs[i][0]\n",
    "    train_df.iat[i, 1] = last_pairs[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15d5f4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>لا تحزن الدنيا ما فيها اشي تحزن عليه</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>لا تحزن ان الله معك</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>لا تحزن على دنا فانيه بل احزن على اخره باقيه</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>لا تخسر قيمتك بكلمه ، ولا تفقد احترامك بزله ، ولا تجعل همك في الدنيا هو حب الناس لك ، فالناس قلوبهم متقلبه قد تحبك اليوم و تكرهك غدا</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>لا تعليق</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>لا تفهمي غلط حبيبتي</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>لا تقنطوا من رحمه الله فهي وسعت كل شيء مهما عصينا فلنا رب كبير رحيم ورحمن</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>لا تياسوا من روح الله ، الله تعالى لا يعجزه شيء ، فكم من مريض شفاه ، وكم من فقير اغناه ، وكم من مشرف على الهلاك نجاه ، وكم من ضال هداه</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>لا حول ولا قوه الا بالله اذا اخذ ما اوهب اسقط ما اوجب</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>لا حول ولا قوه الا بالله العظيم لم اكن اعلم ان نسبه ذكاء العرب منخفضه جدا الى هذا الحد</td>\n",
       "      <td>[52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 78, 79, 80, 82, 83, 84, 85]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>لا حول ولا قوه الا بالله ليش الحرج هدا</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>لا ربنا يرحمنا برحمته</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>لا شو انا مسخره كلكو خنازير</td>\n",
       "      <td>[16, 17, 18, 19, 21, 22, 23, 24, 25, 26]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>لا طبعا التقرب الى الله هو خير علاج للحالات النفسيه</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>لا عنجد زلمه شكلو بخوف</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>لا كرامه في الحب والغرام</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>لا للمفاعل داخل الاردن</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>لا محاله اول شيء يحدث له بعد عودته للمغرب سيتم اغتصابه كالعاهره</td>\n",
       "      <td>[42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>لا مش فاهماك</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>لا مو حقودين ولا شي</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                    Sentence  \\\n",
       "1200                                                                                                    لا تحزن الدنيا ما فيها اشي تحزن عليه   \n",
       "1201                                                                                                                     لا تحزن ان الله معك   \n",
       "1202                                                                                            لا تحزن على دنا فانيه بل احزن على اخره باقيه   \n",
       "1203    لا تخسر قيمتك بكلمه ، ولا تفقد احترامك بزله ، ولا تجعل همك في الدنيا هو حب الناس لك ، فالناس قلوبهم متقلبه قد تحبك اليوم و تكرهك غدا   \n",
       "1204                                                                                                                                لا تعليق   \n",
       "1205                                                                                                                     لا تفهمي غلط حبيبتي   \n",
       "1206                                                               لا تقنطوا من رحمه الله فهي وسعت كل شيء مهما عصينا فلنا رب كبير رحيم ورحمن   \n",
       "1207  لا تياسوا من روح الله ، الله تعالى لا يعجزه شيء ، فكم من مريض شفاه ، وكم من فقير اغناه ، وكم من مشرف على الهلاك نجاه ، وكم من ضال هداه   \n",
       "1208                                                                                   لا حول ولا قوه الا بالله اذا اخذ ما اوهب اسقط ما اوجب   \n",
       "1209                                                  لا حول ولا قوه الا بالله العظيم لم اكن اعلم ان نسبه ذكاء العرب منخفضه جدا الى هذا الحد   \n",
       "1210                                                                                                  لا حول ولا قوه الا بالله ليش الحرج هدا   \n",
       "1211                                                                                                                   لا ربنا يرحمنا برحمته   \n",
       "1212                                                                                                             لا شو انا مسخره كلكو خنازير   \n",
       "1213                                                                                     لا طبعا التقرب الى الله هو خير علاج للحالات النفسيه   \n",
       "1214                                                                                                                  لا عنجد زلمه شكلو بخوف   \n",
       "1215                                                                                                                لا كرامه في الحب والغرام   \n",
       "1216                                                                                                                  لا للمفاعل داخل الاردن   \n",
       "1217                                                                         لا محاله اول شيء يحدث له بعد عودته للمغرب سيتم اغتصابه كالعاهره   \n",
       "1218                                                                                                                            لا مش فاهماك   \n",
       "1219                                                                                                                     لا مو حقودين ولا شي   \n",
       "\n",
       "                                                                                                                 Spans  \n",
       "1200                                                                                                                []  \n",
       "1201                                                                                                                []  \n",
       "1202                                                                                                                []  \n",
       "1203                                                                                                                []  \n",
       "1204                                                                                                                []  \n",
       "1205                                                                                                                []  \n",
       "1206                                                                                                                []  \n",
       "1207                                                                                                                []  \n",
       "1208                                                                                                                []  \n",
       "1209  [52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 75, 76, 78, 79, 80, 82, 83, 84, 85]  \n",
       "1210                                                                                                                []  \n",
       "1211                                                                                                                []  \n",
       "1212                                                                          [16, 17, 18, 19, 21, 22, 23, 24, 25, 26]  \n",
       "1213                                                                                                                []  \n",
       "1214                                                                                                                []  \n",
       "1215                                                                                                                []  \n",
       "1216                                                                                                                []  \n",
       "1217                                      [42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62]  \n",
       "1218                                                                                                                []  \n",
       "1219                                                                                                                []  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show some examples of the final dataset\n",
    "train_df[1200: 1220]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4834ac99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataset to a CSV file\n",
    "train_df.to_csv('train_ready.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cbde7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
