{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_embeddings_128.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## *Note*: you need to turn on the GPU in this Notebook due the large number of parameters of BERT"
      ],
      "metadata": {
        "id": "8tAgr2pf7RkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# clone our github repository\n",
        "!git clone https://github.com/Azzam-Radman/Toxic-Spans-Detection.git"
      ],
      "metadata": {
        "id": "HlMS8s-j0aEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import standard libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# prevent truncation of long sentences during displaying\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "metadata": {
        "id": "d3c0ORHHql-u"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read the datasets\n",
        "try:\n",
        "    # will be implimented if the repo is cloned\n",
        "    df1 = pd.read_excel('/content/Toxic-Spans-Detection/src/dataset/tokenized_1.xlsx')\n",
        "    df2 = pd.read_excel('/content/Toxic-Spans-Detection/src/dataset/tokenized_ready.xlsx')\n",
        "except:\n",
        "    # else read the datasets directly from the repo\n",
        "    df1 = pd.read_excel('https://github.com/Azzam-Radman/Toxic-Spans-Detection/blob/main/src/dataset/tokenized_1.xlsx?raw=true')\n",
        "    df2 = pd.read_excel('https://github.com/Azzam-Radman/Toxic-Spans-Detection/blob/main/src/dataset/tokenized_ready.xlsx?raw=true')"
      ],
      "metadata": {
        "id": "PSKns4tb0lW2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "m40jPvac0qjW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JjZNi2mqah2",
        "outputId": "c30e0ce6-bb58-466c-9631-dfade02036d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow-text==2.7.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "D1_-1IuXqcdr",
        "outputId": "7162a71f-534e-4df7-ea27-2607c8f50c21"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-text==2.7.0\n",
            "  Downloading tensorflow_text-2.7.0-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.8,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text==2.7.0) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (1.19.5)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (12.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (0.37.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (3.10.0.2)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (0.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (3.17.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (1.13.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (0.23.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (1.43.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow-text==2.7.0) (3.1.1)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as tf_text"
      ],
      "metadata": {
        "id": "Pp0z3Yd6qxTQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vyd2Z4gXq0jv",
        "outputId": "66767e4e-3b6b-4ccd-b798-51126966c022"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (2.5.9)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concatenate the two splits of the dataset\n",
        "df1 = df1.iloc[:1798, :].reset_index(drop=True)\n",
        "df2 = df2.iloc[1798:, :].reset_index(drop=True)\n",
        "# concatenate the two splits of the dataset\n",
        "df = pd.concat([df1, df2], axis=0).reset_index(drop=True)\n",
        "# display the head of the dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "JtY4C-zsq0mJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "ade539d9-de47-42e6-f542-b3b7c4bc480c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7d167473-62ed-41ed-9159-90b55b830fc2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>103</th>\n",
              "      <th>104</th>\n",
              "      <th>105</th>\n",
              "      <th>106</th>\n",
              "      <th>107</th>\n",
              "      <th>108</th>\n",
              "      <th>109</th>\n",
              "      <th>110</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>113</th>\n",
              "      <th>114</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "      <th>125</th>\n",
              "      <th>126</th>\n",
              "      <th>127</th>\n",
              "      <th>128</th>\n",
              "      <th>129</th>\n",
              "      <th>130</th>\n",
              "      <th>131</th>\n",
              "      <th>132</th>\n",
              "      <th>133</th>\n",
              "      <th>134</th>\n",
              "      <th>135</th>\n",
              "      <th>136</th>\n",
              "      <th>137</th>\n",
              "      <th>138</th>\n",
              "      <th>139</th>\n",
              "      <th>140</th>\n",
              "      <th>141</th>\n",
              "      <th>142</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>اربد</td>\n",
              "      <td>فيها</td>\n",
              "      <td>جامعات</td>\n",
              "      <td>اكثر</td>\n",
              "      <td>من</td>\n",
              "      <td>عمان</td>\n",
              "      <td>...</td>\n",
              "      <td>وفيها</td>\n",
              "      <td>قد</td>\n",
              "      <td>عمان</td>\n",
              "      <td>ونص</td>\n",
              "      <td>لعيبه</td>\n",
              "      <td>المنتخب</td>\n",
              "      <td>منها</td>\n",
              "      <td>...</td>\n",
              "      <td>و</td>\n",
              "      <td>80</td>\n",
              "      <td>%</td>\n",
              "      <td>من</td>\n",
              "      <td>مطربين</td>\n",
              "      <td>الاردن</td>\n",
              "      <td>منها</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>...</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>الحلو</td>\n",
              "      <td>انكم</td>\n",
              "      <td>بتحكوا</td>\n",
              "      <td>على</td>\n",
              "      <td>اساس</td>\n",
              "      <td>انو</td>\n",
              "      <td>الاردن</td>\n",
              "      <td>ما</td>\n",
              "      <td>فيه</td>\n",
              "      <td>فساد</td>\n",
              "      <td>سرقات</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>...</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>كله</td>\n",
              "      <td>رائع</td>\n",
              "      <td>بجد</td>\n",
              "      <td>ربنا</td>\n",
              "      <td>يكرمك</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>...</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "      <td>pad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 143 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d167473-62ed-41ed-9159-90b55b830fc2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d167473-62ed-41ed-9159-90b55b830fc2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d167473-62ed-41ed-9159-90b55b830fc2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     0     1       2     3      4     5    ...  137  138  139  140  141  142\n",
              "0   اربد  فيها  جامعات  اكثر     من  عمان  ...  pad  pad  pad  pad  pad  pad\n",
              "1      0     0       0     0      0     0  ...  NaN  NaN  NaN  NaN  NaN  NaN\n",
              "2  الحلو  انكم  بتحكوا   على   اساس   انو  ...  pad  pad  pad  pad  pad  pad\n",
              "3      0     0       0     0      0     0  ...  NaN  NaN  NaN  NaN  NaN  NaN\n",
              "4    كله  رائع     بجد  ربنا  يكرمك   pad  ...  pad  pad  pad  pad  pad  pad\n",
              "\n",
              "[5 rows x 143 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function to remove the 'pad' cells in the tokens rows\n",
        "# and remove the corresponding NaNs in the labels rows\n",
        "def remove_pad_nan(word_row, label_row):\n",
        "    \"\"\"\n",
        "    args:\n",
        "    word_row: the row containing words (tokens) with \"pad\" tokens to remove\n",
        "    label_row: the label containig labels (0 or 1) with NaNs to remove\n",
        "    returns two lists with words and labels without pads and NaNs.\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    word_list = word_row.tolist()\n",
        "    label_list = label_row.tolist()\n",
        "    \n",
        "    word_list_cleaned = [word for word in word_list if word != 'pad']\n",
        "    label_list_cleaned = [label for label in label_list if label is not np.nan]\n",
        "    \n",
        "    pair = [word_list_cleaned, label_list_cleaned]\n",
        "    return pair"
      ],
      "metadata": {
        "id": "b9A_v_F9q0rR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = [] # initialize a list to hold the pairs\n",
        "# loop over each couple of rows and pass them to the previous function to extract\n",
        "# the cleaned rows without padding and NaNs\n",
        "for i in range(len(df)):\n",
        "    if i%2 == 0:\n",
        "        pairs.append(remove_pad_nan(df.iloc[i, :], df.iloc[i+1, :]))"
      ],
      "metadata": {
        "id": "eDaiC1mkq0t6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add a space after each token to reconstruct the sentences \n",
        "pairs_with_spaces = [] # initialize a list to hold the new pairs\n",
        "\n",
        "# loop over the pairs\n",
        "for pair in pairs:\n",
        "    words_with_spaces = [] # initialize a list for each iter in the loop to hold the tokens with the spaces\n",
        "    labels_with_spaces = [] # initialize a list for each iter in the loop to hold the labels with the spaces\n",
        "    len_one_pair = len(pair[0]) # extract the lenght of the list\n",
        "    \n",
        "    for i in range(len_one_pair): # loop over the list elements and add the space after each token and each label\n",
        "        words_with_spaces.extend([pair[0][i], ' '])\n",
        "        labels_with_spaces.extend([pair[1][i], ' '])\n",
        "    \n",
        "    new_pair = [words_with_spaces, labels_with_spaces] # create a new pair list of the tokens and labels with spaces\n",
        "    pairs_with_spaces.append(new_pair) # append new_pair list to the pairs_with_spaces list"
      ],
      "metadata": {
        "id": "88bQ0o3u1AS0"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove last space which was added after the last token and after the last label\n",
        "for pair in pairs_with_spaces:\n",
        "    pair[0].pop(-1)\n",
        "    pair[1].pop(-1)"
      ],
      "metadata": {
        "id": "kTYBpx-_1AVC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop over each pair of the pairs_with_spaces list\n",
        "# if the label is 1 (toxic) extract its span\n",
        "# the span is the indexes of the underlying characters of each token\n",
        "for pair in pairs_with_spaces:\n",
        "    # length of the words or labels list\n",
        "    len_one_pair = len(pair[0])\n",
        "    # initialize the toxic spans list and a counter\n",
        "    toxic_spans_list = []\n",
        "    counter = 0\n",
        "    # loop over each item in each list\n",
        "    for idx in range(len_one_pair):\n",
        "        # extract word label from the label list\n",
        "        word_label = pair[1][idx]\n",
        "        # get the word length from the word list\n",
        "        if isinstance(pair[0][idx], str):\n",
        "            len_word = len(pair[0][idx]) # in case the token is a string extract its length\n",
        "        else: \n",
        "            len_word = 1 # else if the token is digit, its length is 1\n",
        "            \n",
        "        if word_label == 0:\n",
        "            counter += len_word # increment the counter by the number of characters of this token\n",
        "        elif word_label == ' ': # in case the token is a space increment the counter by 1\n",
        "            counter += 1\n",
        "        else:\n",
        "            toxic_spans = list(range(counter, counter+len_word)) # create a list of the toxic span of this token\n",
        "            toxic_spans_list.extend(toxic_spans) # extend the toxic spans list with the spans of the current toxic token\n",
        "            counter += len_word # increment the counter by 1\n",
        "            \n",
        "    pair.append(toxic_spans_list) # append the toxic spans list after each pair to the original pair list"
      ],
      "metadata": {
        "id": "w_B-uHo81AX1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# reconstruct the sentences with the spans only \n",
        "last_pairs = [] # initialize a list to hold the final pairs (sentence, toxic spans)\n",
        "for pair in pairs_with_spaces: # loop over each pair\n",
        "    sentence = ''.join(map(str, pair[0])) # construct the sentece and ensure each element is a sting instance\n",
        "    spans = pair[-1] # the last list in each pair is the toxic spans\n",
        "    new_last_pair = [sentence, spans] # construct a new list with the sentece and toxic spans only\n",
        "    last_pairs.append(new_last_pair) # append this list to the last_pairs list"
      ],
      "metadata": {
        "id": "Gz4MixPK1MRz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zeros = np.zeros((len(df)//2, 2)) # initialize a zeros array to hold the place of the sentences and spans the \n",
        "                                  # final dataframe\n",
        "train_df = pd.DataFrame(zeros, columns=['Sentence', 'Spans']) # construct the final dataframe, all values are \n",
        "                                                              # initialized with zeros\n",
        "\n",
        "train_df['Spans'] = train_df['Spans'].astype('str') # change the Spans columns data type to string to accept lists\n",
        "for i in range(len(last_pairs)): # loop over each pair and populate the dataframe\n",
        "    train_df.iloc[i, 0] = last_pairs[i][0]\n",
        "    train_df.iat[i, 1] = last_pairs[i][1]"
      ],
      "metadata": {
        "id": "8sjetvpPrR_9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_setence_embedding(sentences):\n",
        "  \"\"\"\n",
        "  this function preprocesses the text to be ready to\n",
        "  feed to the BERT model, then the 768-length vectors\n",
        "  are extracted for each sentence\n",
        "  return: the encoded sentence\n",
        "  \"\"\"\n",
        "  preprocessed_text = bert_preprocessing(sentences)\n",
        "  encoded_text = bert_encoder(preprocessed_text)\n",
        "  return encoded_text['pooled_output']"
      ],
      "metadata": {
        "id": "VBGoSN0Waf7S"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing layer provided in TensorFlow Hub\n",
        "bert_preprocessing = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3')\n",
        "# BERT layer provided in Tensorflow Hub\n",
        "bert_encoder = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/4')"
      ],
      "metadata": {
        "id": "DW34B7q1agAu"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "Q2njWixhYfgP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "eVsuvpV73uhj",
        "outputId": "7376d8c2-0856-4ef8-c842-2cb76d487c5b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cdbc74bb-1d43-4d72-8a36-d6c179e9d125\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Spans</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>اربد فيها جامعات اكثر من عمان ... وفيها قد عمان ونص لعيبه المنتخب منها ... و 80 % من مطربين الاردن منها</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>الحلو انكم بتحكوا على اساس انو الاردن ما فيه فساد سرقات</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>كله رائع بجد ربنا يكرمك</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>لسانك قذر يا قمامه</td>\n",
              "      <td>[6, 7, 8, 13, 14, 15, 16, 17]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>انا داشره وغير متزوجه ولدي علاقات مشبوه واحشش واحيانا اهرب مخدرات و اجيد التسليك احب ان انكب نفسي وعلاقتي بالمنزل متوتره جد</td>\n",
              "      <td>[4, 5, 6, 7, 8, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 73, 74, 75, 76, 77, 78, 79, 88, 89, 90, 91, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cdbc74bb-1d43-4d72-8a36-d6c179e9d125')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cdbc74bb-1d43-4d72-8a36-d6c179e9d125 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cdbc74bb-1d43-4d72-8a36-d6c179e9d125');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                                                                      Sentence                                                                                                                                                                                                                                                                                  Spans\n",
              "0                      اربد فيها جامعات اكثر من عمان ... وفيها قد عمان ونص لعيبه المنتخب منها ... و 80 % من مطربين الاردن منها                                                                                                                                                                                                                                                                                     []\n",
              "1                                                                      الحلو انكم بتحكوا على اساس انو الاردن ما فيه فساد سرقات                                                                                                                                                                                                                                                                                     []\n",
              "2                                                                                                      كله رائع بجد ربنا يكرمك                                                                                                                                                                                                                                                                                     []\n",
              "3                                                                                                           لسانك قذر يا قمامه                                                                                                                                                                                                                                                          [6, 7, 8, 13, 14, 15, 16, 17]\n",
              "4  انا داشره وغير متزوجه ولدي علاقات مشبوه واحشش واحيانا اهرب مخدرات و اجيد التسليك احب ان انكب نفسي وعلاقتي بالمنزل متوتره جد  [4, 5, 6, 7, 8, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 73, 74, 75, 76, 77, 78, 79, 88, 89, 90, 91, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_list = []\n",
        "for i in tqdm(range(len(train_df))):\n",
        "  sentence = [train_df.iloc[i, 0]]\n",
        "  embed = get_setence_embedding(sentence)\n",
        "  embeddings_list.append(embed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBpSm9FnYMys",
        "outputId": "2cbc40f6-1be5-41e9-a495-06782f3e3bf0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1799/1799 [04:20<00:00,  6.91it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zeros = np.zeros((len(embeddings_list), 768))\n",
        "bert_embeddings_df = pd.DataFrame(zeros, columns=[f'{i}' for i in range(768)])\n",
        "bert_embeddings_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S5CIVW_YSgk",
        "outputId": "8e4dba78-abea-4545-9a38-e3dbbd337d2c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1799, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(bert_embeddings_df)):\n",
        "  bert_embeddings_df.iloc[i, :] = embeddings_list[i][0].numpy()"
      ],
      "metadata": {
        "id": "XQiIFWbdYSvo"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['is_toxic'] = train_df['Spans'].apply(lambda x: int(0) if x==[] else 1)\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "j9CDla835M4s",
        "outputId": "cf560dd1-03b0-4152-a3b4-2b4a5e7fe669"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-95bd120b-c0e0-4fb6-9453-9e3a543ab251\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Spans</th>\n",
              "      <th>is_toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>اربد فيها جامعات اكثر من عمان ... وفيها قد عمان ونص لعيبه المنتخب منها ... و 80 % من مطربين الاردن منها</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>الحلو انكم بتحكوا على اساس انو الاردن ما فيه فساد سرقات</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>كله رائع بجد ربنا يكرمك</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>لسانك قذر يا قمامه</td>\n",
              "      <td>[6, 7, 8, 13, 14, 15, 16, 17]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>انا داشره وغير متزوجه ولدي علاقات مشبوه واحشش واحيانا اهرب مخدرات و اجيد التسليك احب ان انكب نفسي وعلاقتي بالمنزل متوتره جد</td>\n",
              "      <td>[4, 5, 6, 7, 8, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 73, 74, 75, 76, 77, 78, 79, 88, 89, 90, 91, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95bd120b-c0e0-4fb6-9453-9e3a543ab251')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-95bd120b-c0e0-4fb6-9453-9e3a543ab251 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-95bd120b-c0e0-4fb6-9453-9e3a543ab251');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                                                                                      Sentence  ... is_toxic\n",
              "0                      اربد فيها جامعات اكثر من عمان ... وفيها قد عمان ونص لعيبه المنتخب منها ... و 80 % من مطربين الاردن منها  ...        0\n",
              "1                                                                      الحلو انكم بتحكوا على اساس انو الاردن ما فيه فساد سرقات  ...        0\n",
              "2                                                                                                      كله رائع بجد ربنا يكرمك  ...        0\n",
              "3                                                                                                           لسانك قذر يا قمامه  ...        1\n",
              "4  انا داشره وغير متزوجه ولدي علاقات مشبوه واحشش واحيانا اهرب مخدرات و اجيد التسليك احب ان انكب نفسي وعلاقتي بالمنزل متوتره جد  ...        1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model to create the 128 vectors\n",
        "def my_model():\n",
        "  inputs = tf.keras.layers.Input(shape=(768,))\n",
        "  custom_embeddings = tf.keras.layers.Dense(128, activation='relu', name='custom_embeddings')(inputs)\n",
        "  final_output = tf.keras.layers.Dense(1, activation='sigmoid')(custom_embeddings)\n",
        "  model = tf.keras.Model(inputs=inputs, outputs=final_output)\n",
        "  return model"
      ],
      "metadata": {
        "id": "vhGkaZE8agDq"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define, compile and train the model\n",
        "model = my_model()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "              metrics=tf.keras.metrics.AUC())\n",
        "model.fit(bert_embeddings_df, train_df['is_toxic'], epochs=20, batch_size=64, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q82EniyagG-",
        "outputId": "c5ce89e7-214d-4a48-c5f9-6fc13a9ef7b7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "26/26 [==============================] - 1s 16ms/step - loss: 0.5986 - auc_2: 0.5344 - val_loss: 0.5560 - val_auc_2: 0.6654\n",
            "Epoch 2/20\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5789 - auc_2: 0.5618 - val_loss: 0.5553 - val_auc_2: 0.6793\n",
            "Epoch 3/20\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5710 - auc_2: 0.6080 - val_loss: 0.5509 - val_auc_2: 0.7023\n",
            "Epoch 4/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5670 - auc_2: 0.6349 - val_loss: 0.5461 - val_auc_2: 0.7220\n",
            "Epoch 5/20\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5620 - auc_2: 0.6522 - val_loss: 0.5449 - val_auc_2: 0.7295\n",
            "Epoch 6/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5587 - auc_2: 0.6611 - val_loss: 0.5420 - val_auc_2: 0.7446\n",
            "Epoch 7/20\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5555 - auc_2: 0.6705 - val_loss: 0.5413 - val_auc_2: 0.7504\n",
            "Epoch 8/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5509 - auc_2: 0.6819 - val_loss: 0.5321 - val_auc_2: 0.7593\n",
            "Epoch 9/20\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5487 - auc_2: 0.6887 - val_loss: 0.5311 - val_auc_2: 0.7617\n",
            "Epoch 10/20\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5446 - auc_2: 0.6984 - val_loss: 0.5284 - val_auc_2: 0.7643\n",
            "Epoch 11/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5410 - auc_2: 0.7033 - val_loss: 0.5266 - val_auc_2: 0.7680\n",
            "Epoch 12/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5364 - auc_2: 0.7176 - val_loss: 0.5218 - val_auc_2: 0.7706\n",
            "Epoch 13/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5336 - auc_2: 0.7205 - val_loss: 0.5212 - val_auc_2: 0.7734\n",
            "Epoch 14/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5307 - auc_2: 0.7252 - val_loss: 0.5194 - val_auc_2: 0.7716\n",
            "Epoch 15/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5297 - auc_2: 0.7193 - val_loss: 0.5170 - val_auc_2: 0.7784\n",
            "Epoch 16/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5257 - auc_2: 0.7294 - val_loss: 0.5143 - val_auc_2: 0.7718\n",
            "Epoch 17/20\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5232 - auc_2: 0.7340 - val_loss: 0.5124 - val_auc_2: 0.7748\n",
            "Epoch 18/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5197 - auc_2: 0.7396 - val_loss: 0.5187 - val_auc_2: 0.7644\n",
            "Epoch 19/20\n",
            "26/26 [==============================] - 0s 5ms/step - loss: 0.5196 - auc_2: 0.7361 - val_loss: 0.5104 - val_auc_2: 0.7708\n",
            "Epoch 20/20\n",
            "26/26 [==============================] - 0s 4ms/step - loss: 0.5165 - auc_2: 0.7429 - val_loss: 0.5088 - val_auc_2: 0.7727\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4644989790>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the output from the layer named \"custom_embeddings\" where the outputs are 128-dimensional vectors\n",
        "layer_name = 'custom_embeddings'\n",
        "intermediate_model = tf.keras.Model(inputs=model.input,\n",
        "                                    outputs=model.get_layer(layer_name).output)\n",
        "embeddings_128 = intermediate_model.predict(bert_embeddings_df, batch_size=64)"
      ],
      "metadata": {
        "id": "iQ9Paqgcg7Ru"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the embeddings to a CSV file\n",
        "pd.DataFrame(embeddings_128, columns=[f'{i}' for i in range(embeddings_128.shape[1])]).to_csv('bert_embeddings_128.csv', index=False)"
      ],
      "metadata": {
        "id": "xrC4h5SThvQ3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lKnOJjlB1qIl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
